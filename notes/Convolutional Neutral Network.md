# Convolution Neutral Network



### 一、卷积神经层级架构

#### 1.1 数据输入层

数据输入层主要做的是对原始数据进行预处理。

* 去均值：把输入数据各个维度都中心化为0，其目的就是把样本的中心拉回到坐标系原点上。
* 归一化：幅度归一化到同样的范围，即减少各维度数据取值范围的差异而带来的干扰，一般归一至0到1的范围
* PCA/白化：PCA降维；白化是对数据各个特征轴上的幅度归一化

#### 1.2 卷积计算层

卷积计算层是卷积神经网络最重要的一个层次，有两个关键操作：**局部关联**和**窗口滑动**

* 深度：每个神经元看作一个滤波器 filter，有多少个神经元，深度depth就是多少
* 步长：步长stride是窗口滑动一次的长度
* 填充值：有些时候滑动窗口无法遍历所有的像素，这时候就需要在原先矩阵填充几层，填进去的就是填充值padding，通常使用zero-padding也就是使用0来填充

##### 卷积的计算

卷积操作中，一个 3×3×3 的子节点矩阵和一个 3×3×3 的 filter 对应元素相乘，得到的是一个 3×3×3 的矩阵，此时将该矩阵所有元素求和，得到一个 1×1×1 的矩阵，将其再加上 filter 的 bias，经过激活函数得到最后的结果，将最后的结果填入到对应的输出矩阵中。

<img src="E:\李云昊\计算机视觉\img\卷积计算01.jpg" alt="卷积计算01" style="zoom:80%;" />

这里的蓝色矩阵就是输入的图像，粉色矩阵就是卷积层的神经元，这里表示了有两个神经元（w0,w1）。绿色矩阵就是经过卷积运算后的输出矩阵，这里的步长设置为2。该实例中输入矩阵为7×7×3，滤波器为3×3×3，而输出矩阵为3×3×2，滑动窗口每移动一个步长，**计算三层的窗口矩阵与滤波器矩阵对应位相乘再相加，最后加上偏置值得到一个输出**（例如图中就是 0 + (-2-2) + 0 + 1 = -3 ）的计算，最终得到3×3的矩阵，因为有两个滤波器所以输出矩阵层数为2。

##### 参数共享机制

在卷积层中每个神经元连接数据窗的权重是固定的，每个神经元只关注一个特性。神经元就是图像处理中的滤波器，比如边缘检测专用的Sobel滤波器，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合。

#### 1.3 ReLU激励层

把卷积层输出结果做非线性映射。CNN采用的激励函数(激活函数)一般是ReLU( The Rectified Linear Unit 修正线性单元 )，它的特点是收敛快，求梯度简单，但是比较脆弱。

神经网络中每一层进行矩阵运算之后得到结果，激活函数或者说是激励函数就是为了给该结果添加非线性用的，常见的激活函数有阶跃函数、Sigmoid函数和ReLU函数，基础CNN中通常使用ReLU。三种函数见下图所示：

<img src="E:\李云昊\计算机视觉\img\激活函数.jpg" alt="三种激活函数" style="zoom:80%;" />

#### 1.4 池化层

池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。简而言之，**如果输入是图像的话，那么池化层的最主要作用就是压缩图像**。

##### 具体作用

* 特征不变性：图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。
* 特征降维：一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来。
* 在一定程度上防止过拟合，更方便优化。

##### 池化层方法

池化层常方法有 Max Pooling 和 Average Pooling，实际使用比较多的是Max Pooling。

<img src="E:\李云昊\计算机视觉\img\max pooling.jpg" alt="Max Pooling" style="zoom:67%;" />

对于每个2 * 2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2 * 2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。同样的 Average Pooling 就是去平均值，不再展开。

*池化层一般不改变矩阵深度，只改变长和宽*

#### 1.5 全连接层

CNN中两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部，也就是跟传统的神经网络神经元的连接方式是一样的。经过多轮卷积层和池化层的处理后，在CNN的最后一般由1到2个全连接层来给出最后的分类结果。经过几轮卷积和池化操作，可以认为图像中的信息已经被抽象成了信息含量更高的特征。我们可以将卷积和池化看成自动图像提取的过程，在特征提取完成后，仍然**需要使用全连接层来完成分类任务**。

### Notes

##### channel是什么？

* 最初输入的图片样本的 channels ，取决于图片类型，比如RGB类型就是3。
* 卷积操作完成后输出的 out_channels ，取决于卷积核的数量。此时的 out_channels 也会作为下一次卷积时的卷积核的 in_channels。
* 卷积核中的 in_channels ，刚刚2中已经说了，就是上一次卷积的 out_channels ，如果是第一次做卷积，就是1中样本图片的 channels 。



### Reference

* [一文让你理解什么是卷积神经网络  简书](https://www.jianshu.com/p/191d1e21f7ed)

* [卷积神经网络(CNN) 手记](https://www.imooc.com/article/68983)
