# Tracking Objects as Points

论文链接：[Tracking Objects as Points](https://arxiv.org/abs/2004.01177)

### 一、简介

原文提出了一种新的MOT检测器Center Tracker，它融合了point-based跟踪和同时进行检测和跟踪的思想（主流是TBD范式）。Center Track使用CenterNet检测器来定位目标中心。模型输入为一对相邻帧的图像以及以点表示的前帧轨迹的热图上，训练检测器输出一个当前目标中心和之前帧目标中心补偿向量，作为中心点的一个属性。仅根据预测偏移量与前一帧检测到的中心点之间的距离进行贪婪匹配，即可实现目标关联。追踪器实现端到端训练。

CenterTrack主要有两个优点，首先它简化了跟踪条件检测。每个对象用点表示，对象群用热图中的所有点表示。检测器直接提取热图，在帧之间将他们关联来推理目标。其次，基于点的追踪节省了目标关联的时间。简单的位移预测（中心位移补偿）类似于稀疏光流，允许目标在不同帧之间进行关联。位移由前帧决定，可以根据前帧的关联联合来推测当前帧的目标。

### 二、CenterTrack 实现

Cente Track是基于Center Net实现的，关于CenterNet的介绍详见[Classic Algorithms](../Classic Algorithms.md)相关部分。

在每一个时刻CenterTrack获取当前时刻的一帧（W×H×3）和前一帧图像作为输入，同时还获取前一帧中得到的轨迹列表，每一个轨迹只包含其在上一帧中的object，用位置、大小、detection confidence（相当于检测得分）和ID表示。目标就是将当前帧中的对象和上一帧的轨迹进行匹配。要做到这点主要有两个难点，一是如何找到帧中的所有对象（包括被遮挡的对象），二是如何关联不同时间帧上的对象，接下来就来介绍作者如何解决这两个问题。

#### 2.1 条件追踪检测

CenterNet检测器基本上已经获取了tracking所需要所有信息（位置、大小和detection confidence），但是它无法获得当时不可见（被遮挡）的对象。很自然的一个解决方案是在传入当前帧输入的时候，传入一个过去相邻帧的信息，用于评估场景变化并潜在恢复当前帧的遮挡目标。因此CenterTrack同时还传入了一个过去帧的热图，每个目标用点表示，热图使用和CenterNet中一样的高斯渲染函数渲染。渲染置信度高于阈值τ的点以便减少假阳性检测的提升。**中心结构和CenterNet基本相同，只是多了额外的四个通道的数据**。虽然解决了时间不一致性，但仍有可能会在时序上不匹配。

#### 2.2 偏移连接

为了完成时序连接，**CenterTrack预测了一个额外的2维位移输出**（W/R×H/R×2），对于每一个检测结果对象的位置我们获取其在两帧上的差别，我们使用相同的回归函数来学习这个位移作为位置和坐标的微调：

<img src="..\img\CenterTrack公式01.jpg" style="zoom:80%;" />

当这个位移损失足够低，使用一个贪婪匹配算法来完成在时序上连接目标。就是说对每个当前帧上的对象贪婪匹配（按照detection confidence排序），如果距离k之内都没有找到匹配那么就创建一个新的tracklet，κ定义为每个预测轨迹的预测边界框的高和宽的几何均值。关于轨迹的rebirth，也就是像是一段时间后又出现，原文中测试时取保留32帧，但训练时不保留。

#### 2.3 训练

在视频数据上的训练，一个主要的挑战是需要传入的前帧热图是可靠的。推理时，这个热图可以包含自定义多的目标，错误定位目标甚至假正性。但是训练时传入的真实轨迹不会有这些错误，所以会使用一些数据增强策略来增强模型健壮性。比如加入高斯噪音、随即添加一些FP样本或者随机移除一些detections实验中，不一定非要使用相邻的前帧，可以使用t帧附近的随机采样防止过拟合。
